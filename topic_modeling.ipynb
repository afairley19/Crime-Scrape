{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_modeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOD73sXpIgmB79goWxSmpW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afairley19/nlp_colab/blob/master/topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d_SDnL_Y0bf",
        "outputId": "ce780f39-73e0-420b-9111-bf783a84ec52"
      },
      "source": [
        "import os\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"] \n",
        "! java -version\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.6.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 69kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 51.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130389 sha256=da25fa4f14547dcaa97e4bf5768239351cab6663fc0fb980ab4210026812f68d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/84/3f15673db521fbc4e8e0ec3677a019ba1458b2cb70f0f7738c221511ef32/spark_nlp-2.6.3-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 18.5MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSB9fgnaZ439",
        "outputId": "91acff80-5b53-46ed-e1a2-1026d0936d12"
      },
      "source": [
        "! pip install --ignore-installed spark-nlp==2.6.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spark-nlp==2.6.3\n",
            "  Using cached https://files.pythonhosted.org/packages/84/84/3f15673db521fbc4e8e0ec3677a019ba1458b2cb70f0f7738c221511ef32/spark_nlp-2.6.3-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPwFQiSEZw_K",
        "outputId": "4c5cbfb5-b7fd-4dcd-fe3b-0651e5368b58"
      },
      "source": [
        "\n",
        "! sudo update-alternatives --config java"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "  0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "* 2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t53eFZLeZ84V",
        "outputId": "1f8001ef-8cbb-4585-9a6c-63d18e5d46b4"
      },
      "source": [
        "from pyspark.sql import SparkSession \n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.pretrained import PretrainedPipeline \n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "print(\"Spark NLP version: \", sparknlp.version()) \n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.6.3\n",
            "Apache Spark version:  2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "hR07vcEY-uit",
        "outputId": "f9f1c25e-5e31-418f-8d90-ff7896506e6d"
      },
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "data_path = 'coronavirus-text-only-1000.txt'\n",
        "with open(data_path, 'r') as f:\n",
        "    lines = f.read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa5f369c-0dee-4651-b2eb-3b66aa8869d2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa5f369c-0dee-4651-b2eb-3b66aa8869d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving coronavirus-text-only-1000.txt to coronavirus-text-only-1000.txt\n",
            "User uploaded file \"coronavirus-text-only-1000.txt\" with length 149569 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGI08QFqeLRR",
        "outputId": "ab4dc889-6857-4d87-d2a6-efb222da16da"
      },
      "source": [
        "## if you are reading file from local storage\n",
        "file_location = r'./coronavirus-text-only-1000.txt'\n",
        "# if you are reading file from hdfs\n",
        "#file_location = r'hdfs:\\\\\\path\\file' \n",
        "file_type = \"csv\"\n",
        "# CSV options\n",
        "infer_schema = \"true\"\n",
        "first_row_is_header = \"true\"\n",
        "delimiter = \",\"\n",
        "df = spark.read.format(file_type)\\\n",
        ".option(\"inferSchema\", infer_schema)\\\n",
        ".option(\"header\", first_row_is_header)\\\n",
        ".option(\"sep\", delimiter)\\\n",
        ".load(file_location)\n",
        "# Verify the count\n",
        "df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bYRKtnLbwyN"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"document\")\\\n",
        ".setCleanupMode(\"shrink\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHHgwSScRSv"
      },
      "source": [
        "tokenizer = Tokenizer()\\\n",
        ".setInputCols([\"document\"])\\\n",
        ".setOutputCol(\"token\")\\\n",
        ".setSplitChars(['-'])\\\n",
        ".setContextChars(['(', ')', '?', '!'])\\\n",
        ".setSplitPattern(\"'\")\\\n",
        ".setMaxLength(0)\\\n",
        ".setMaxLength(99999)\\\n",
        ".setCaseSensitiveExceptions(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taN0N49zcsLJ"
      },
      "source": [
        "normalizer = Normalizer()\\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCol(\"normalized\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh9FOOqcc6dB"
      },
      "source": [
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        ".setInputCols(\"normalized\")\\\n",
        ".setOutputCol(\"cleanTokens\")\\\n",
        ".setStopWords([\"coronavirus\"\"])\\\n",
        ".setCaseSensitive(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cco41TLndKEl"
      },
      "source": [
        "stemmer = Stemmer()\\\n",
        ".setInputCols([\"cleanTokens\"])\\\n",
        ".setOutputCol(\"stem\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhFJ59qYda1n"
      },
      "source": [
        "finisher = Finisher()\\\n",
        ".setInputCols([\"stem\"])\\\n",
        ".setOutputCols([\"tokens\"])\\\n",
        ".setOutputAsArray(True)\\\n",
        ".setCleanAnnotations(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d40AZRncds1m"
      },
      "source": [
        "nlp_pipeline = Pipeline( stages=[document_assembler,\n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner,\n",
        "            stemmer,\n",
        "            finisher])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HQH4tfVd8F7",
        "outputId": "3a515da0-da9a-4686-f382-040bf3329335"
      },
      "source": [
        "nlp_model = nlp_pipeline.fit(df)\n",
        "processed_df = nlp_model.transform(df)\n",
        "tokens_df = processed_df.select('tokens').limit(10000) \n",
        "tokens_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|              tokens|\n",
            "+--------------------+\n",
            "|[studi, look, at,...|\n",
            "|[erictopol, these...|\n",
            "|[npr, work, mom, ...|\n",
            "|[harveywalk, al, ...|\n",
            "|[cnnee, farmacuti...|\n",
            "|[reutersworld, hu...|\n",
            "|[cnn, thi, illino...|\n",
            "|[censelio, argent...|\n",
            "|[jilevin, trump, ...|\n",
            "|[propublica, pres...|\n",
            "|[nsw, close, vict...|\n",
            "|[aslavitt, trumpä...|\n",
            "|[claytravi, death...|\n",
            "|[jamesgunn, ve, k...|\n",
            "|[natashafatah, sc...|\n",
            "|[crissl, yäôall, ...|\n",
            "|[censelio, argent...|\n",
            "|[villarruelclau, ...|\n",
            "|[jaxalemani, äúal...|\n",
            "|[jamesgunn, ve, k...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcXK5YVOfC5K"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=500, minDF=3.0)\n",
        "# train the model\n",
        "cv_model = cv.fit(tokens_df)\n",
        "# transform the data. Output column name will be features.\n",
        "vectorized_tokens = cv_model.transform(tokens_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l4tDO8-fhR5",
        "outputId": "2d1e1f58-3cab-4d63-fd7a-35b01c0339d0"
      },
      "source": [
        "from pyspark.ml.clustering import LDA\n",
        "num_topics = 5\n",
        "lda = LDA(k=num_topics, maxIter= 500)\n",
        "model = lda.fit(vectorized_tokens)\n",
        "ll = model.logLikelihood(vectorized_tokens)\n",
        "lp = model.logPerplexity(vectorized_tokens)\n",
        "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
        "print(\"The upper bound on perplexity: \" + str(lp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lower bound on the log likelihood of the entire corpus: -49900.972540208335\n",
            "The upper bound on perplexity: 5.2990307465443705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF6yccCXf5ar",
        "outputId": "76acc10e-2354-4497-d20f-2006347934e0"
      },
      "source": [
        "# extract vocabulary from CountVectorizer\n",
        "vocab = cv_model.vocabulary \n",
        "topics = model.describeTopics() \n",
        "topics_rdd = topics.rdd \n",
        "topics_words = topics_rdd\\\n",
        "    .map(lambda row: row['termIndices'])\\\n",
        "    .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
        "    .collect()\n",
        "for idx, topic in enumerate(topics_words):\n",
        "    print(\"topic: {}\".format(idx))\n",
        "    print(\"*\"*25)\n",
        "    for word in topic:\n",
        "        print(word)\n",
        "    print(\"*\"*25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic: 0\n",
            "*************************\n",
            "\n",
            "have\n",
            "ar\n",
            "peopl\n",
            "case\n",
            "new\n",
            "death\n",
            "on\n",
            "who\n",
            "their\n",
            "*************************\n",
            "topic: 1\n",
            "*************************\n",
            "work\n",
            "hour\n",
            "on\n",
            "npr\n",
            "more\n",
            "than\n",
            "but\n",
            "recent\n",
            "now\n",
            "isä\n",
            "*************************\n",
            "topic: 2\n",
            "*************************\n",
            "i\n",
            "thi\n",
            "for\n",
            "with\n",
            "be\n",
            "ha\n",
            "will\n",
            "covid\n",
            "from\n",
            "get\n",
            "*************************\n",
            "topic: 3\n",
            "*************************\n",
            "lo\n",
            "caso\n",
            "covid\n",
            "la\n",
            "con\n",
            "del\n",
            "m\n",
            "da\n",
            "mil\n",
            "se\n",
            "*************************\n",
            "topic: 4\n",
            "*************************\n",
            "she\n",
            "trump\n",
            "even\n",
            "donald\n",
            "job\n",
            "could\n",
            "chines\n",
            "than\n",
            "said\n",
            "t\n",
            "*************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBjw9vsAf5eJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}